{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Using CNN for image classification using CIFAR-10 dataset"
      ],
      "metadata": {
        "id": "96SogH_dGfhR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup of Data Pipeline"
      ],
      "metadata": {
        "id": "csPia0ScIFAh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SYOYlXMuGaSs",
        "outputId": "fca8302a-4126-4e38-88e3-ab6eeec8227e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow opencv-python matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os"
      ],
      "metadata": {
        "id": "AljE2GzPIDrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Limit the GPU consumption by the program for avoiding error"
      ],
      "metadata": {
        "id": "yD7zlYihJcsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpus=tf.config.experimental.list_physical_devices(\"GPU\") # Stores a list of available GPUs in gpus\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu,True) # Limits the memory"
      ],
      "metadata": {
        "id": "_0fEGt2FJC5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "B6Lsb9HNK11G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using CIFAR10 dataset"
      ],
      "metadata": {
        "id": "9RAzfCroL18e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(train_X,train_y),(val_X,val_y)=datasets.cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8ujkhM5LGhL",
        "outputId": "3db6f3d4-9886-4e71-e81f-0b192e1177d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reshaping train_y for our requirements\n"
      ],
      "metadata": {
        "id": "CD3f2CDnN9vr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_X.shape, val_X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZKh1K_sOW6f",
        "outputId": "3f1f144a-02a7-40bd-9323-82d4ce1cf230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3), (10000, 32, 32, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y.shape, val_y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Md8CUaUaObnB",
        "outputId": "668b13d9-90ca-4d40-daca-f4b561eeaf96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 1), (10000, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As our X has around 32x32 images and in y we have only 1 column there needs to be reshaping done"
      ],
      "metadata": {
        "id": "LhLBYVqcOqUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This train_y is a 2D array, for our classification having a 1D array works as well\n",
        "train_y=train_y.reshape(-1)\n",
        "val_y=val_y.reshape(-1)"
      ],
      "metadata": {
        "id": "OEKZhBC4OhJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes=[\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]"
      ],
      "metadata": {
        "id": "VaeiBBCqNIJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_sample(X,y,index):\n",
        "    # Resizing the plot to look at image properly\n",
        "    plt.figure(figsize=(15,2))\n",
        "    # Looking at image\n",
        "    plt.imshow(X[index])\n",
        "    plt.xlabel(classes[y[index]])\n"
      ],
      "metadata": {
        "id": "8m04qGrWLgRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_sample(train_X,train_y,3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "bRa4se5xMC9B",
        "outputId": "55ad86ce-9464-4cbb-ed6f-127eb1b1fa0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The data has RGB channels i.e values from 0 to 255\n",
        "## For simplification we can convert these to 0/1 i.e binary values by simply dividing by 255"
      ],
      "metadata": {
        "id": "EY7GqWGdSOJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_X=train_X/255\n",
        "val_X=val_X/255"
      ],
      "metadata": {
        "id": "M7CzsB4RRvKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a simple ANN model for image classification"
      ],
      "metadata": {
        "id": "5yC3rsgMSqNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann=models.Sequential([\n",
        "    layers.Flatten(input_shape=(32,32,3)),\n",
        "    layers.Dense(3000, activation=\"relu\"),\n",
        "    layers.Dense(2000, activation=\"relu\"),\n",
        "    layers.Dense(25, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "ann.compile(optimizer=\"SGD\",\n",
        "            loss=\"sparse_categorical_crossentropy\",\n",
        "            metrics=[\"accuracy\"])\n",
        "\n",
        "ann.fit(train_X,train_y,epochs=7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCNilzs7SlxR",
        "outputId": "abe10aa5-ab92-4a8b-9826-f4151c2d9f6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "1563/1563 [==============================] - 169s 108ms/step - loss: 1.8770 - accuracy: 0.3194\n",
            "Epoch 2/7\n",
            "1563/1563 [==============================] - 163s 104ms/step - loss: 1.6507 - accuracy: 0.4117\n",
            "Epoch 3/7\n",
            "1563/1563 [==============================] - 160s 102ms/step - loss: 1.5551 - accuracy: 0.4476\n",
            "Epoch 4/7\n",
            "1563/1563 [==============================] - 158s 101ms/step - loss: 1.4867 - accuracy: 0.4723\n",
            "Epoch 5/7\n",
            "1563/1563 [==============================] - 174s 111ms/step - loss: 1.4320 - accuracy: 0.4934\n",
            "Epoch 6/7\n",
            "1563/1563 [==============================] - 213s 136ms/step - loss: 1.3835 - accuracy: 0.5090\n",
            "Epoch 7/7\n",
            "1563/1563 [==============================] - 240s 154ms/step - loss: 1.3436 - accuracy: 0.5230\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e075ce2c550>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now to see how our model performs in prediction"
      ],
      "metadata": {
        "id": "TL2vkwDwXnDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import numpy as np\n",
        "predictions_y=ann.predict(val_X)\n",
        "predn_classes=[np.argmax(element) for element in predictions_y]\n",
        "\n",
        "print(\"Classification Report: \\n\",classification_report(val_y,predn_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-vx9pc1XlLY",
        "outputId": "10adaa6b-139d-4353-f8e1-9972611ecaff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 10s 33ms/step\n",
            "Classification Report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.50      0.54      1000\n",
            "           1       0.68      0.61      0.64      1000\n",
            "           2       0.36      0.31      0.33      1000\n",
            "           3       0.40      0.17      0.24      1000\n",
            "           4       0.40      0.46      0.42      1000\n",
            "           5       0.48      0.34      0.39      1000\n",
            "           6       0.32      0.84      0.46      1000\n",
            "           7       0.67      0.46      0.54      1000\n",
            "           8       0.58      0.66      0.62      1000\n",
            "           9       0.67      0.44      0.53      1000\n",
            "\n",
            "    accuracy                           0.48     10000\n",
            "   macro avg       0.51      0.48      0.47     10000\n",
            "weighted avg       0.51      0.48      0.47     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now using CNN to train our images"
      ],
      "metadata": {
        "id": "D0R2C0LOYte0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn=models.Sequential([\n",
        "    layers.Conv2D(filters=32, kernel_size=(3,3),activation=\"relu\",input_shape=(32,32,3)),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    layers.Conv2D(filters=64, kernel_size=(3,3),activation=\"relu\"),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64,activation=\"relu\"),\n",
        "    layers.Dense(128,activation=\"relu\"),\n",
        "    layers.Dense(10,activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "Hy5yEUGBUBPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer=\"adam\",\n",
        "            loss=\"sparse_categorical_crossentropy\",\n",
        "            metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "G4iH1n49br-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(train_X,train_y,epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEzzGk4qcCLG",
        "outputId": "a04f6969-602b-49f3-8667-9c75872b48b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "1563/1563 [==============================] - 58s 36ms/step - loss: 1.4804 - accuracy: 0.4613\n",
            "Epoch 2/25\n",
            "1563/1563 [==============================] - 56s 36ms/step - loss: 1.1131 - accuracy: 0.6062\n",
            "Epoch 3/25\n",
            "1563/1563 [==============================] - 55s 35ms/step - loss: 0.9755 - accuracy: 0.6581\n",
            "Epoch 4/25\n",
            "1563/1563 [==============================] - 56s 36ms/step - loss: 0.8913 - accuracy: 0.6886\n",
            "Epoch 5/25\n",
            "1563/1563 [==============================] - 55s 35ms/step - loss: 0.8253 - accuracy: 0.7136\n",
            "Epoch 6/25\n",
            "1563/1563 [==============================] - 55s 35ms/step - loss: 0.7712 - accuracy: 0.7319\n",
            "Epoch 7/25\n",
            "1563/1563 [==============================] - 55s 35ms/step - loss: 0.7234 - accuracy: 0.7484\n",
            "Epoch 8/25\n",
            "1563/1563 [==============================] - 55s 35ms/step - loss: 0.6852 - accuracy: 0.7600\n",
            "Epoch 9/25\n",
            "1563/1563 [==============================] - 61s 39ms/step - loss: 0.6474 - accuracy: 0.7721\n",
            "Epoch 10/25\n",
            "1563/1563 [==============================] - 74s 48ms/step - loss: 0.6117 - accuracy: 0.7846\n",
            "Epoch 11/25\n",
            "1563/1563 [==============================] - 78s 50ms/step - loss: 0.5782 - accuracy: 0.7970\n",
            "Epoch 12/25\n",
            "1563/1563 [==============================] - 55s 35ms/step - loss: 0.5496 - accuracy: 0.8056\n",
            "Epoch 13/25\n",
            "1563/1563 [==============================] - 55s 35ms/step - loss: 0.5197 - accuracy: 0.8171\n",
            "Epoch 14/25\n",
            "1563/1563 [==============================] - 55s 35ms/step - loss: 0.4966 - accuracy: 0.8239\n",
            "Epoch 15/25\n",
            "1563/1563 [==============================] - 55s 35ms/step - loss: 0.4730 - accuracy: 0.8322\n",
            "Epoch 16/25\n",
            "1563/1563 [==============================] - 55s 35ms/step - loss: 0.4515 - accuracy: 0.8406\n",
            "Epoch 17/25\n",
            "1563/1563 [==============================] - 58s 37ms/step - loss: 0.4296 - accuracy: 0.8478\n",
            "Epoch 18/25\n",
            "1563/1563 [==============================] - 55s 35ms/step - loss: 0.4120 - accuracy: 0.8539\n",
            "Epoch 19/25\n",
            "1563/1563 [==============================] - 54s 35ms/step - loss: 0.3885 - accuracy: 0.8615\n",
            "Epoch 20/25\n",
            "1563/1563 [==============================] - 55s 35ms/step - loss: 0.3733 - accuracy: 0.8677\n",
            "Epoch 21/25\n",
            "1563/1563 [==============================] - 55s 35ms/step - loss: 0.3638 - accuracy: 0.8690\n",
            "Epoch 22/25\n",
            "1563/1563 [==============================] - 54s 35ms/step - loss: 0.3417 - accuracy: 0.8782\n",
            "Epoch 23/25\n",
            "1563/1563 [==============================] - 54s 35ms/step - loss: 0.3277 - accuracy: 0.8819\n",
            "Epoch 24/25\n",
            "1563/1563 [==============================] - 54s 35ms/step - loss: 0.3211 - accuracy: 0.8835\n",
            "Epoch 25/25\n",
            "1563/1563 [==============================] - 55s 35ms/step - loss: 0.2979 - accuracy: 0.8938\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e075e336e30>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.evaluate(val_X,val_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dv55oZgeB0Q",
        "outputId": "95bc7461-3800-43c9-9ff0-0857edbb92ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 11ms/step - loss: 1.4772 - accuracy: 0.6749\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.477201223373413, 0.6748999953269958]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=cnn.predict(val_X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNDhvU7xeOw1",
        "outputId": "a7890264-ee7b-4e22-a753-960ca2387e31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 11ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pclass=[np.argmax(element) for element in y_pred]"
      ],
      "metadata": {
        "id": "qGCB9xmheeZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_y[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcAcBFdxiFbu",
        "outputId": "cef7d78f-ea03-4ac3-f8da-41e9f41baae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 8, 8, 0, 6], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pclass[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YItXEGuciIZN",
        "outputId": "378d9015-96fd-4eac-d1d1-a2a4aee18bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 8, 8, 0, 6]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y3Ep8e0PiM3o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}